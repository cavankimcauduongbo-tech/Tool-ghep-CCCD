import streamlit as st
from PIL import Image, ImageDraw, ImageEnhance
import cv2
import numpy as np
from rembg import remove, new_session
import io
import gc
from streamlit_image_coordinates import streamlit_image_coordinates

# --- C·∫§U H√åNH ---
st.set_page_config(page_title="Tool CCCD V19 (Hybrid)", page_icon="üÜî", layout="wide")

# --- CORE LOGIC CHUNG ---

@st.cache_resource
def load_ai_session():
    return new_session("u2netp")

def pixel_from_mm(mm, dpi=300):
    return int(mm * dpi / 25.4)

def order_points(pts):
    """S·∫Øp x·∫øp 4 ƒëi·ªÉm: TL, TR, BR, BL"""
    rect = np.zeros((4, 2), dtype="float32")
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]
    rect[2] = pts[np.argmax(s)]
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]
    rect[3] = pts[np.argmax(diff)]
    return rect

# --- LOGIC T·ª∞ ƒê·ªòNG (AUTO) ---
def crop_center_ratio(img, target_ratio=1.5858):
    h, w = img.shape[:2]
    current_ratio = w / h
    if current_ratio > target_ratio:
        new_w = int(h * target_ratio)
        offset = (w - new_w) // 2
        return img[:, offset:offset+new_w]
    elif current_ratio < target_ratio:
        new_h = int(w / target_ratio)
        offset = (h - new_h) // 2
        return img[offset:offset+new_h, :]
    return img

def auto_process_image(image_pil, session):
    # Chu·∫©n h√≥a
    image_pil = image_pil.convert("RGB")
    enhancer = ImageEnhance.Contrast(image_pil)
    image_pil = enhancer.enhance(1.5) # TƒÉng t∆∞∆°ng ph·∫£n
    
    img_np = np.array(image_pil)
    
    try:
        # 1. L·∫•y Mask
        mask_pil = remove(image_pil, session=session, only_mask=True)
        mask = np.array(mask_pil)
        
        # 2. T√¨m Contour
        cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not cnts: return image_pil
        c = max(cnts, key=cv2.contourArea)
        
        # 3. MinAreaRect
        rect = cv2.minAreaRect(c)
        box = cv2.boxPoints(rect)
        box = box.astype(int)
        
        # 4. Warp
        rect_pts = order_points(box)
        w_box = np.linalg.norm(rect_pts[0] - rect_pts[1])
        h_box = np.linalg.norm(rect_pts[0] - rect_pts[3])
        
        dst_w, dst_h = int(w_box), int(h_box)
        
        if h_box > w_box:
            rect_pts = np.array([rect_pts[3], rect_pts[0], rect_pts[1], rect_pts[2]], dtype="float32")
            dst_w, dst_h = dst_h, dst_w # Swap

        dst_pts = np.array([[0, 0], [dst_w-1, 0], [dst_w-1, dst_h-1], [0, dst_h-1]], dtype="float32")
        M = cv2.getPerspectiveTransform(rect_pts, dst_pts)
        warped = cv2.warpPerspective(img_np, M, (dst_w, dst_h), flags=cv2.INTER_LANCZOS4)
        
        # 5. Crop t·ª∑ l·ªá chu·∫©n (1.585)
        final_img = crop_center_ratio(warped, 1.5858)
        
        return Image.fromarray(final_img)
    except:
        return image_pil

# --- LOGIC CH·ªàNH TAY (MANUAL) ---
def warp_from_points(image_pil, points):
    img_np = np.array(image_pil.convert("RGB"))
    pts = np.array(points, dtype="float32")
    rect_pts = order_points(pts)

    dst_w, dst_h = 1011, 638
    dst_pts = np.array([[0, 0], [dst_w-1, 0], [dst_w-1, dst_h-1], [0, dst_h-1]], dtype="float32")
    
    w_src = np.linalg.norm(rect_pts[0] - rect_pts[1])
    h_src = np.linalg.norm(rect_pts[0] - rect_pts[3])
    
    if h_src > w_src:
        rect_pts = np.array([rect_pts[3], rect_pts[0], rect_pts[1], rect_pts[2]], dtype="float32")

    M = cv2.getPerspectiveTransform(rect_pts, dst_pts)
    warped = cv2.warpPerspective(img_np, M, (dst_w, dst_h), flags=cv2.INTER_LANCZOS4)
    return Image.fromarray(warped)

# --- UI COMPONENT: Manual Crop ---
def manual_crop_ui(label, key_prefix, image_pil):
    pts_key = f"{key_prefix}_points"
    if pts_key not in st.session_state: st.session_state[pts_key] = []

    w_orig, h_orig = image_pil.size
    display_width = 500
    ratio = display_width / w_orig
    display_height = int(h_orig * ratio)
    img_resized = image_pil.resize((display_width, display_height))
    
    st.markdown(f"**{label} (Ch·ªânh tay)**")
    st.caption("Click 4 g√≥c -> B·∫•m C·∫Øt")

    img_draw = img_resized.copy()
    draw = ImageDraw.Draw(img_draw)
    points = st.session_state[pts_key]
    
    for i, p in enumerate(points):
        px, py = int(p[0]*ratio), int(p[1]*ratio)
        color = "#00FF00" if i == 3 else "#FF0000"
        draw.ellipse((px-5, py-5, px+5, py+5), fill=color, outline="white")
        draw.text((px+8, py), str(i+1), fill="yellow")

    value = streamlit_image_coordinates(img_draw, key=f"coord_{key_prefix}", width=display_width)

    if value:
        real_x = value["x"] / ratio
        real_y = value["y"] / ratio
        
        # Check duplicate click
        is_dup = False
        if points:
            last = points[-1]
            if abs(last[0]-real_x) < 5 and abs(last[1]-real_y) < 5: is_dup = True
        
        if not is_dup and len(points) < 4:
            points.append((real_x, real_y))
            st.session_state[pts_key] = points
            st.rerun()

    c1, c2 = st.columns([1, 2])
    with c1:
        if st.button("üóëÔ∏è X√≥a", key=f"del_{key_prefix}"):
            st.session_state[pts_key] = []
            st.rerun()
    with c2:
        if len(points) == 4:
            if st.button("‚úÇÔ∏è C·∫Øt Ngay", key=f"cut_{key_prefix}", type="primary"):
                return warp_from_points(image_pil, points)
    return None

# --- MAIN APP ---

def main():
    st.markdown("<h1 style='text-align: center; color: #d35400;'>üÜî TOOL CCCD V19 (HYBRID)</h1>", unsafe_allow_html=True)
    
    # --- 1. CH·ªåN CH·∫æ ƒê·ªò ---
    st.markdown("### ‚öôÔ∏è C√†i ƒë·∫∑t ch·∫ø ƒë·ªô")
    mode = st.radio("Ch·ªçn c√°ch x·ª≠ l√Ω:", ["ü§ñ T·ª± ƒë·ªông (AI Auto)", "üñêÔ∏è Ch·ªânh tay (Click 4 ƒëi·ªÉm)"], horizontal=True)
    
    # Load AI n·∫øu c·∫ßn
    session = None
    if "T·ª± ƒë·ªông" in mode:
        with st.spinner("ƒêang t·∫£i AI..."):
            session = load_ai_session()

    # --- 2. UPLOAD ·∫¢NH ---
    st.markdown("---")
    col1, col2 = st.columns(2)
    with col1: f_file = st.file_uploader("M·∫∑t Tr∆∞·ªõc", type=['jpg','png','jpeg'], key="f")
    with col2: b_file = st.file_uploader("M·∫∑t Sau", type=['jpg','png','jpeg'], key="b")

    img1_final = None
    img2_final = None

    # --- 3. X·ª¨ L√ù ·∫¢NH ---
    if f_file and b_file:
        img1 = Image.open(f_file)
        img2 = Image.open(b_file)

        # A. CH·∫æ ƒê·ªò T·ª∞ ƒê·ªòNG
        if "T·ª± ƒë·ªông" in mode:
            if st.button("üöÄ X·ª¨ L√ù T·ª∞ ƒê·ªòNG NGAY", type="primary", use_container_width=True):
                with st.spinner("AI ƒëang x·ª≠ l√Ω..."):
                    img1_final = auto_process_image(img1, session)
                    img2_final = auto_process_image(img2, session)
                    
                    # L∆∞u v√†o session ƒë·ªÉ kh√¥ng b·ªã m·∫•t khi rerun
                    st.session_state['res_auto_1'] = img1_final
                    st.session_state['res_auto_2'] = img2_final
            
            # Load l·∫°i k·∫øt qu·∫£ n·∫øu ƒë√£ c√≥
            if 'res_auto_1' in st.session_state:
                img1_final = st.session_state['res_auto_1']
                img2_final = st.session_state['res_auto_2']
                
                # Hi·ªÉn th·ªã k·∫øt qu·∫£ con
                c1, c2 = st.columns(2)
                with c1: st.image(img1_final, caption="M·∫∑t Tr∆∞·ªõc (Auto)", width=300)
                with c2: st.image(img2_final, caption="M·∫∑t Sau (Auto)", width=300)

        # B. CH·∫æ ƒê·ªò CH·ªàNH TAY
        else:
            c1, c2 = st.columns(2)
            with c1:
                res1 = manual_crop_ui("M·∫∑t Tr∆∞·ªõc", "f_man", img1)
                if res1: st.session_state['res_man_1'] = res1
                if 'res_man_1' in st.session_state: 
                    st.image(st.session_state['res_man_1'], width=300, caption="ƒê√£ c·∫Øt")
                    img1_final = st.session_state['res_man_1']
            
            with c2:
                res2 = manual_crop_ui("M·∫∑t Sau", "b_man", img2)
                if res2: st.session_state['res_man_2'] = res2
                if 'res_man_2' in st.session_state: 
                    st.image(st.session_state['res_man_2'], width=300, caption="ƒê√£ c·∫Øt")
                    img2_final = st.session_state['res_man_2']

    # --- 4. GH√âP A4 & XEM TR∆Ø·ªöC (PREVIEW) ---
    if img1_final and img2_final:
        st.markdown("---")
        st.subheader("üìÑ K·∫æT QU·∫¢ CU·ªêI C√ôNG (A4 Preview)")
        
        # X·ª≠ l√Ω gh√©p
        TARGET_W, TARGET_H = 1011, 638
        scan1 = img1_final.resize((TARGET_W, TARGET_H), Image.Resampling.LANCZOS)
        scan2 = img2_final.resize((TARGET_W, TARGET_H), Image.Resampling.LANCZOS)

        A4_W, A4_H = pixel_from_mm(210, 300), pixel_from_mm(297, 300)
        canvas = Image.new('RGB', (A4_W, A4_H), 'white')
        
        cx = A4_W // 2
        gap = 350
        sy = (A4_H - (TARGET_H * 2 + gap)) // 2 

        canvas.paste(scan1, (cx - TARGET_W // 2, sy))
        canvas.paste(scan2, (cx - TARGET_W // 2, sy + TARGET_H + gap))
        
        # --- HI·ªÇN TH·ªä PREVIEW A4 ---
        st.image(canvas, caption="B·∫£n xem tr∆∞·ªõc A4 (ƒê√£ s·∫µn s√†ng in)", use_container_width=True, output_format="JPEG")
        
        # --- N√öT T·∫¢I XU·ªêNG ---
        pdf_buffer = io.BytesIO()
        canvas.save(pdf_buffer, "PDF", resolution=300.0)
        
        st.download_button(
            label="üì• T·∫¢I FILE PDF A4 V·ªÄ M√ÅY",
            data=pdf_buffer.getvalue(),
            file_name="CCCD_V19_Hybrid.pdf",
            mime="application/pdf",
            type="primary",
            use_container_width=True
        )

    st.markdown("---")
    st.markdown("<div style='text-align: center; color: grey;'>App created by C√† VƒÉn Kim - ATP</div>", unsafe_allow_html=True)

if __name__ == "__main__":
    main()
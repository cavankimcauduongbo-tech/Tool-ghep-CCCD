import streamlit as st
from PIL import Image
import cv2
import numpy as np
from rembg import remove, new_session
import io
import gc # Th∆∞ vi·ªán d·ªçn r√°c b·ªô nh·ªõ

# --- C·∫§U H√åNH ---
st.set_page_config(page_title="Tool Gh√©p CCCD V5 (Lite)", page_icon="üÜî", layout="centered")

# --- 1. CORE LOGIC (V5: LITE MODEL + ANTI-SKEW) ---

@st.cache_resource
def load_ai_session():
    # QUAN TR·ªåNG: D√πng 'u2netp' (b·∫£n nh·∫π) thay v√¨ 'u2net' ƒë·ªÉ tr√°nh s·∫≠p server
    # Model n√†y ch·ªâ n·∫∑ng 4MB so v·ªõi 176MB c·ªßa b·∫£n g·ªëc
    return new_session("u2netp")

def pixel_from_mm(mm, dpi=300):
    return int(mm * dpi / 25.4)

def order_points(pts):
    """S·∫Øp x·∫øp 4 ƒëi·ªÉm: TL, TR, BR, BL"""
    rect = np.zeros((4, 2), dtype="float32")
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]
    rect[2] = pts[np.argmax(s)]
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]
    rect[3] = pts[np.argmax(diff)]
    return rect

def smart_scan_v5(image_pil, session):
    """
    V5: Resize tr∆∞·ªõc khi x·ª≠ l√Ω + B√†o m√≤n mask ƒë·ªÉ ch·ªëng nghi√™ng
    """
    # 1. Resize ·∫£nh ƒë·∫ßu v√†o n·∫øu qu√° l·ªõn (Gi·∫£m t·∫£i RAM c·ª±c m·∫°nh)
    max_size = 1500
    w, h = image_pil.size
    if max(w, h) > max_size:
        ratio = max_size / max(w, h)
        new_size = (int(w * ratio), int(h * ratio))
        image_pil = image_pil.resize(new_size, Image.Resampling.LANCZOS)

    img_np = np.array(image_pil)
    
    try:
        # 2. L·∫•y Mask (D√πng model nh·∫π u2netp)
        # Ch·ªâ l·∫•y mask ƒëen tr·∫Øng
        mask_pil = remove(image_pil, session=session, only_mask=True)
        mask = np.array(mask_pil)
        
        # 3. K·ª∏ THU·∫¨T M·ªöI: B√†o m√≤n (Erosion)
        # Lo·∫°i b·ªè b√≥ng m·ªù/vi·ªÅn rƒÉng c∆∞a -> Gi√∫p khung bao √¥m s√°t th·∫ª th·∫≠t
        kernel = np.ones((5,5), np.uint8)
        mask = cv2.erode(mask, kernel, iterations=2)
        
        # 4. T√¨m Contour
        cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not cnts: return image_pil
        
        c = max(cnts, key=cv2.contourArea)
        
        # 5. MinAreaRect (T√¨m h·ªôp bao)
        rect = cv2.minAreaRect(c)
        box = cv2.boxPoints(rect)
        box = np.int0(box)
        
        # 6. √âp ph·∫≥ng (Perspective Transform)
        dst_w, dst_h = 1011, 638 # Chu·∫©n pixel scan
        rect_pts = order_points(box)
        dst_pts = np.array([[0, 0], [dst_w-1, 0], [dst_w-1, dst_h-1], [0, dst_h-1]], dtype="float32")
        
        M = cv2.getPerspectiveTransform(rect_pts, dst_pts)
        
        # C·∫Øt t·ª´ ·∫£nh g·ªëc (ƒë·ªÉ gi·ªØ m√†u s·∫Øc ƒë·∫πp nh·∫•t)
        warped = cv2.warpPerspective(img_np, M, (dst_w, dst_h), flags=cv2.INTER_LANCZOS4)
        
        # X√≥a n·ªÅn l·∫ßn cu·ªëi tr√™n ·∫£nh ƒë√£ c·∫Øt ph·∫≥ng (l√∫c n√†y ·∫£nh nh·ªè n√™n x·ª≠ l√Ω r·∫•t nhanh)
        warped_pil = Image.fromarray(warped)
        final_clean = remove(warped_pil, session=session) 
        
        return final_clean

    except Exception as e:
        st.error(f"L·ªói x·ª≠ l√Ω: {e}")
        return image_pil

# --- 2. GIAO DI·ªÜN WEB ---

def main():
    st.markdown("<h1 style='text-align: center; color: #8e44ad;'>üÜî TOOL V5 (LITE & SHARP)</h1>", unsafe_allow_html=True)
    st.caption("Phi√™n b·∫£n t·ªëi ∆∞u b·ªô nh·ªõ & Ch·ªëng nghi√™ng")
    
    use_ai = st.checkbox("B·∫≠t AI (Ch·∫ø ƒë·ªô Lite)", value=True)
    
    session = None
    if use_ai:
        with st.spinner("ƒêang t·∫£i AI Lite..."):
            session = load_ai_session()

    col1, col2 = st.columns(2)
    with col1: f_file = st.file_uploader("M·∫∑t Tr∆∞·ªõc", type=['jpg','png','jpeg'], key="f")
    with col2: b_file = st.file_uploader("M·∫∑t Sau", type=['jpg','png','jpeg'], key="b")

    if f_file and b_file:
        if st.button("üöÄ X·ª¨ L√ù NGAY", type="primary", use_container_width=True):
            try:
                # D·ªçn r√°c b·ªô nh·ªõ tr∆∞·ªõc khi ch·∫°y
                gc.collect()
                
                with st.spinner("ƒêang x·ª≠ l√Ω (Si√™u t·ªëc)..."):
                    img1 = Image.open(f_file)
                    img2 = Image.open(b_file)

                    if use_ai:
                        scan1 = smart_scan_v5(img1, session)
                        scan2 = smart_scan_v5(img2, session)
                    else:
                        scan1, scan2 = img1, img2

                    # Gh√©p A4
                    A4_W, A4_H = 2480, 3508
                    target_w, target_h = 1011, 638
                    
                    scan1 = scan1.resize((target_w, target_h), Image.Resampling.LANCZOS)
                    scan2 = scan2.resize((target_w, target_h), Image.Resampling.LANCZOS)

                    canvas = Image.new('RGB', (A4_W, A4_H), 'white')
                    cx = A4_W // 2
                    gap = 300
                    sy = (A4_H - (target_h * 2 + gap)) // 2 

                    canvas.paste(scan1, (cx - target_w // 2, sy), scan1)
                    canvas.paste(scan2, (cx - target_w // 2, sy + target_h + gap), scan2)

                    st.success("Th√†nh c√¥ng!")
                    st.image(canvas, caption="K·∫øt qu·∫£ V5", use_container_width=True)

                    pdf_buffer = io.BytesIO()
                    canvas.save(pdf_buffer, "PDF", resolution=300.0)
                    
                    st.download_button("üì• T·∫¢I PDF", pdf_buffer.getvalue(), "CCCD_V5.pdf", "application/pdf", type="primary")
                    
                    # Gi·∫£i ph√≥ng b·ªô nh·ªõ ngay l·∫≠p t·ª©c
                    del scan1, scan2, canvas, img1, img2
                    gc.collect()

            except Exception as e:
                st.error(f"L·ªói: {e}. H√£y th·ª≠ ·∫£nh nh·∫π h∆°n.")

    st.markdown("---")
    st.markdown("<div style='text-align: center; color: grey;'>App created by C√† VƒÉn Kim - ATP</div>", unsafe_allow_html=True)

if __name__ == "__main__":
    main()
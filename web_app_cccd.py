import streamlit as st
from PIL import Image, ImageEnhance
import cv2
import numpy as np
from rembg import remove, new_session
import io
import gc

# --- C·∫§U H√åNH ---
st.set_page_config(page_title="Tool CCCD V13 (Auto Pro)", page_icon="üÜî", layout="centered")

# --- CORE LOGIC ---

@st.cache_resource
def load_ai_session():
    return new_session("u2netp")

def pixel_from_mm(mm, dpi=300):
    return int(mm * dpi / 25.4)

def order_points(pts):
    """S·∫Øp x·∫øp 4 ƒëi·ªÉm: TL, TR, BR, BL"""
    rect = np.zeros((4, 2), dtype="float32")
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]
    rect[2] = pts[np.argmax(s)]
    diff = np.diff(pts, axis=1)
    rect[1] = pts[np.argmin(diff)]
    rect[3] = pts[np.argmax(diff)]
    return rect

def get_extreme_points(mask):
    """
    T√¨m 4 ƒëi·ªÉm c·ª±c tr·ªã c·ªßa contour thay v√¨ t√¨m h·ªôp bao (minAreaRect).
    Gi√∫p lo·∫°i b·ªè c√°c ph·∫ßn b√≥ng l·ªìi ra ·ªü c·∫°nh b√™n.
    """
    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not cnts: return None
    c = max(cnts, key=cv2.contourArea)
    
    # T√¨m 4 ƒëi·ªÉm c·ª±c: Tr√°i nh·∫•t, Ph·∫£i nh·∫•t, Tr√™n c√πng, D∆∞·ªõi c√πng
    extLeft = tuple(c[c[:, :, 0].argmin()][0])
    extRight = tuple(c[c[:, :, 0].argmax()][0])
    extTop = tuple(c[c[:, :, 1].argmin()][0])
    extBot = tuple(c[c[:, :, 1].argmax()][0])
    
    # Gom l·∫°i th√†nh 4 ƒëi·ªÉm g√≥c gi·∫£ ƒë·ªãnh
    # L∆∞u √Ω: ƒê√¢y l√† c√°ch x·∫•p x·ªâ h√¨nh thoi, c·∫ßn bi·∫øn ƒë·ªïi v·ªÅ h√¨nh ch·ªØ nh·∫≠t
    # N√™n d√πng approxPolyDP s·∫Ω t·ªët h∆°n cho h√¨nh ch·ªØ nh·∫≠t c·ª©ng
    
    peri = cv2.arcLength(c, True)
    approx = cv2.approxPolyDP(c, 0.04 * peri, True) # TƒÉng h·ªá s·ªë l√™n 0.04 ƒë·ªÉ b·∫Øt g√≥c c·ª©ng h∆°n
    
    if len(approx) == 4:
        return approx.reshape(4, 2)
    else:
        # N·∫øu kh√¥ng ra 4 g√≥c, quay v·ªÅ minAreaRect nh∆∞ng thu nh·ªè box l·∫°i 5%
        rect = cv2.minAreaRect(c)
        box = cv2.boxPoints(rect)
        return box

def smart_auto_v13(image_pil, session):
    # 1. TƒÉng c∆∞·ªùng ·∫£nh ƒë·∫ßu v√†o ƒë·ªÉ AI d·ªÖ nh√¨n
    image_pil = image_pil.convert("RGB")
    enhancer = ImageEnhance.Contrast(image_pil)
    image_pil = enhancer.enhance(1.5) # TƒÉng t∆∞∆°ng ph·∫£n
    
    # Resize
    max_dim = 1500
    w, h = image_pil.size
    scale = 1.0
    if max(w, h) > max_dim:
        scale = max_dim / max(w, h)
        new_w, new_h = int(w * scale), int(h * scale)
        image_pil = image_pil.resize((new_w, new_h), Image.Resampling.LANCZOS)
    
    img_np = np.array(image_pil)
    
    try:
        # 2. L·∫•y Mask
        mask_pil = remove(image_pil, session=session, only_mask=True)
        mask = np.array(mask_pil)
        
        # 3. K·ª∏ THU·∫¨T M·ªöI: Morphological Close
        # L·∫•p ƒë·∫ßy c√°c l·ªó h·ªïng b√™n trong th·∫ª (n·∫øu c√≥) v√† l√†m m∆∞·ª£t vi·ªÅn
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 15))
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
        
        # 4. T√¨m ƒëi·ªÉm g√≥c th√¥ng minh
        box = get_extreme_points(mask)
        if box is None: return image_pil
        
        box = box.astype(int)
        
        # 5. √âp ph·∫≥ng chu·∫©n t·ª∑ l·ªá
        rect_pts = order_points(box)
        
        # T·ª± ƒë·ªông xoay ngang
        w_box = np.linalg.norm(rect_pts[0] - rect_pts[1])
        h_box = np.linalg.norm(rect_pts[0] - rect_pts[3])
        
        if h_box > w_box:
            rect_pts = np.array([rect_pts[3], rect_pts[0], rect_pts[1], rect_pts[2]], dtype="float32")
        
        # K√≠ch th∆∞·ªõc ƒë√≠ch chu·∫©n ID-1 (Pixel 300dpi)
        dst_w = 1011
        dst_h = 638
        
        dst_pts = np.array([[0, 0], [dst_w-1, 0], [dst_w-1, dst_h-1], [0, dst_h-1]], dtype="float32")
        
        M = cv2.getPerspectiveTransform(rect_pts, dst_pts)
        warped = cv2.warpPerspective(img_np, M, (dst_w, dst_h), flags=cv2.INTER_LANCZOS4)
        
        # 6. G·ªçt nh·∫π vi·ªÅn (Auto-Shave) 10px ƒë·ªÉ lo·∫°i b·ªè m√©p th·ª´a
        # V√¨ ƒë√£ √©p ƒë√∫ng k√≠ch th∆∞·ªõc 1011x638 n√™n g·ªçt 10px l√† an to√†n
        shave = 10
        warped_clean = warped[shave:dst_h-shave, shave:dst_w-shave]
        
        return Image.fromarray(warped_clean)

    except Exception as e:
        st.warning(f"L·ªói x·ª≠ l√Ω: {e}. D√πng ·∫£nh g·ªëc.")
        return image_pil

# --- GIAO DI·ªÜN WEB ---

def main():
    st.markdown("<h1 style='text-align: center; color: #2980b9;'>üÜî TOOL V13 (AUTO PRO)</h1>", unsafe_allow_html=True)
    st.caption("T·ª± ƒë·ªông ho√†n to√†n - Kh√¥ng c·∫ßn ch·ªânh tay")
    
    use_ai = st.checkbox("B·∫≠t ch·∫ø ƒë·ªô Auto", value=True)
    session = None
    if use_ai:
        with st.spinner("ƒêang kh·ªüi ƒë·ªông h·ªá th·ªëng..."):
            session = load_ai_session()

    col1, col2 = st.columns(2)
    with col1: f_file = st.file_uploader("M·∫∑t Tr∆∞·ªõc", type=['jpg','png','jpeg'], key="f")
    with col2: b_file = st.file_uploader("M·∫∑t Sau", type=['jpg','png','jpeg'], key="b")

    if f_file and b_file:
        if st.button("üöÄ X·ª¨ L√ù T·ª∞ ƒê·ªòNG", type="primary", use_container_width=True):
            try:
                gc.collect()
                with st.spinner("ƒêang ph√¢n t√≠ch v√† c·∫Øt g·ªçt..."):
                    img1 = Image.open(f_file)
                    img2 = Image.open(b_file)

                    if use_ai:
                        scan1 = smart_auto_v13(img1, session)
                        scan2 = smart_auto_v13(img2, session)
                    else:
                        scan1, scan2 = img1, img2

                    # --- GH√âP A4 ---
                    # Quy chu·∫©n k√≠ch th∆∞·ªõc sau khi g·ªçt
                    # Ban ƒë·∫ßu 1011x638 -> G·ªçt 10px m·ªói b√™n -> C√≤n 991x618
                    # C·∫ßn resize l·∫°i v·ªÅ 1011x638 ƒë·ªÉ in ra ƒë√∫ng k√≠ch th∆∞·ªõc th·∫≠t
                    
                    TARGET_W = pixel_from_mm(85.6, 300)
                    TARGET_H = pixel_from_mm(53.98, 300)
                    
                    scan1 = scan1.resize((TARGET_W, TARGET_H), Image.Resampling.LANCZOS)
                    scan2 = scan2.resize((TARGET_W, TARGET_H), Image.Resampling.LANCZOS)

                    A4_W, A4_H = pixel_from_mm(210, 300), pixel_from_mm(297, 300)
                    canvas = Image.new('RGB', (A4_W, A4_H), 'white')
                    
                    cx = A4_W // 2
                    gap = 350
                    sy = (A4_H - (TARGET_H * 2 + gap)) // 2 

                    canvas.paste(scan1, (cx - TARGET_W // 2, sy))
                    canvas.paste(scan2, (cx - TARGET_W // 2, sy + TARGET_H + gap))

                    st.success("Xong! ·∫¢nh ƒë√£ ƒë∆∞·ª£c n·∫Øn th·∫≥ng t·ª± ƒë·ªông.")
                    st.image(canvas, caption="K·∫øt qu·∫£ V13 Auto", use_container_width=True)

                    pdf_buffer = io.BytesIO()
                    canvas.save(pdf_buffer, "PDF", resolution=300.0)
                    
                    st.download_button("üì• T·∫¢I PDF", pdf_buffer.getvalue(), "CCCD_Auto_V13.pdf", "application/pdf", type="primary")
                    
                gc.collect()

            except Exception as e:
                st.error(f"L·ªói: {e}")

    st.markdown("---")
    st.markdown("<div style='text-align: center; color: grey;'>App created by C√† VƒÉn Kim - ATP</div>", unsafe_allow_html=True)

if __name__ == "__main__":
    main()
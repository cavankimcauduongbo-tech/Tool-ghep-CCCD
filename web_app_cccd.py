import streamlit as st
from PIL import Image, ImageDraw, ImageFont
import cv2
import numpy as np
from rembg import remove, new_session
import io
import gc

# --- C·∫§U H√åNH ---
st.set_page_config(page_title="Tool CCCD V15 (Ch·ªânh Ph·ªëi C·∫£nh)", page_icon="üÜî", layout="centered")

# --- CORE LOGIC ---

@st.cache_resource
def load_ai_session():
    return new_session("u2netp")

def pixel_from_mm(mm, dpi=300):
    return int(mm * dpi / 25.4)

def get_default_points(img_pil, session):
    """
    D√πng AI ƒëo√°n tr∆∞·ªõc 4 g√≥c ƒë·ªÉ b·∫°n ƒë·ª° ph·∫£i k√©o nhi·ªÅu.
    Tr·∫£ v·ªÅ dict ch·ª©a 4 c·∫∑p t·ªça ƒë·ªô: TL, TR, BR, BL
    """
    w, h = img_pil.size
    # M·∫∑c ƒë·ªãnh l√† 4 g√≥c ·∫£nh l√πi v√†o 10%
    pad_x = int(w * 0.1)
    pad_y = int(h * 0.1)
    
    default_pts = {
        "tl": [pad_x, pad_y],          # Top-Left
        "tr": [w - pad_x, pad_y],      # Top-Right
        "br": [w - pad_x, h - pad_y],  # Bot-Right
        "bl": [pad_x, h - pad_y]       # Bot-Left
    }

    try:
        # Resize nh·ªè ƒë·ªÉ AI ch·∫°y nhanh
        img_np = np.array(img_pil.convert("RGB"))
        small = cv2.resize(img_np, (0,0), fx=0.5, fy=0.5)
        small_pil = Image.fromarray(small)
        
        mask = remove(small_pil, session=session, only_mask=True)
        mask = np.array(mask)
        
        cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if cnts:
            c = max(cnts, key=cv2.contourArea)
            peri = cv2.arcLength(c, True)
            approx = cv2.approxPolyDP(c, 0.04 * peri, True)
            
            if len(approx) == 4:
                # Map l·∫°i v·ªÅ k√≠ch th∆∞·ªõc g·ªëc (nh√¢n 2)
                pts = approx.reshape(4, 2) * 2
                
                # S·∫Øp x·∫øp ƒëi·ªÉm
                s = pts.sum(axis=1)
                diff = pts[:, 0] - pts[:, 1] # x - y (Logic kh√°c x√≠u)
                # Logic s·∫Øp x·∫øp th·ªß c√¥ng an to√†n h∆°n
                # TL: t·ªïng nh·ªè nh·∫•t, BR: t·ªïng l·ªõn nh·∫•t
                # TR: hi·ªáu x-y l·ªõn nh·∫•t, BL: hi·ªáu x-y nh·ªè nh·∫•t (ho·∫∑c ng∆∞·ª£c l·∫°i t√πy h·ªá tr·ª•c)
                # D√πng logic sort theo Y r·ªìi theo X cho ch·∫Øc
                
                # C√°ch s·∫Øp x·∫øp ƒë∆°n gi·∫£n nh·∫•t:
                # Top: 2 ƒëi·ªÉm c√≥ Y nh·ªè nh·∫•t -> Trong ƒë√≥ X nh·ªè l√† TL, X l·ªõn l√† TR
                # Bot: 2 ƒëi·ªÉm c√≥ Y l·ªõn nh·∫•t -> Trong ƒë√≥ X nh·ªè l√† BL, X l·ªõn l√† BR
                pts = pts[pts[:, 1].argsort()] # Sort theo Y
                top = pts[:2]
                bot = pts[2:]
                
                top = top[top[:, 0].argsort()] # Sort theo X
                bot = bot[bot[:, 0].argsort()]
                
                default_pts["tl"] = top[0].tolist()
                default_pts["tr"] = top[1].tolist()
                default_pts["bl"] = bot[0].tolist()
                default_pts["br"] = bot[1].tolist()

    except:
        pass # N·∫øu AI l·ªói th√¨ d√πng m·∫∑c ƒë·ªãnh
        
    return default_pts

def warp_perspective_manual(img_pil, pts_dict):
    """
    Bi·∫øn ƒë·ªïi ph·ªëi c·∫£nh t·ª´ 4 ƒëi·ªÉm ng∆∞·ªùi d√πng ch·ªçn
    """
    img_np = np.array(img_pil.convert("RGB"))
    
    # 4 ƒëi·ªÉm ngu·ªìn t·ª´ ng∆∞·ªùi d√πng
    src_pts = np.array([
        pts_dict["tl"],
        pts_dict["tr"],
        pts_dict["br"],
        pts_dict["bl"]
    ], dtype="float32")
    
    # 4 ƒëi·ªÉm ƒë√≠ch (K√≠ch th∆∞·ªõc chu·∫©n ID-1 300DPI)
    # 85.6mm x 53.98mm => 1011 x 638 pixel
    dst_w, dst_h = 1011, 638
    
    dst_pts = np.array([
        [0, 0],           # TL
        [dst_w - 1, 0],   # TR
        [dst_w - 1, dst_h - 1], # BR
        [0, dst_h - 1]    # BL
    ], dtype="float32")
    
    # T√≠nh ma tr·∫≠n bi·∫øn ƒë·ªïi
    M = cv2.getPerspectiveTransform(src_pts, dst_pts)
    
    # Warp (√©p ph·∫≥ng)
    warped = cv2.warpPerspective(img_np, M, (dst_w, dst_h), flags=cv2.INTER_LANCZOS4)
    
    return Image.fromarray(warped)

def draw_guide(img_pil, pts):
    """V·∫Ω khung n·ªëi 4 ƒëi·ªÉm ƒë·ªÉ ng∆∞·ªùi d√πng cƒÉn ch·ªânh"""
    draw_img = img_pil.copy()
    draw = ImageDraw.Draw(draw_img)
    
    p = [tuple(pts["tl"]), tuple(pts["tr"]), tuple(pts["br"]), tuple(pts["bl"])]
    
    # V·∫Ω ƒëa gi√°c n·ªëi
    draw.polygon(p, outline="#00FF00", width=4)
    
    # V·∫Ω ch·∫•m tr√≤n to r√µ
    r = 15
    # TL - ƒê·ªè
    draw.ellipse((p[0][0]-r, p[0][1]-r, p[0][0]+r, p[0][1]+r), fill="red", outline="white", width=2)
    # TR - Xanh l√°
    draw.ellipse((p[1][0]-r, p[1][1]-r, p[1][0]+r, p[1][1]+r), fill="green", outline="white", width=2)
    # BR - Xanh d∆∞∆°ng
    draw.ellipse((p[2][0]-r, p[2][1]-r, p[2][0]+r, p[2][1]+r), fill="blue", outline="white", width=2)
    # BL - V√†ng
    draw.ellipse((p[3][0]-r, p[3][1]-r, p[3][0]+r, p[3][1]+r), fill="yellow", outline="white", width=2)
    
    return draw_img

# --- UI COMPONENT ---

def adjustment_ui(label, key_prefix, uploaded_file, session):
    if not uploaded_file: return None
    
    img = Image.open(uploaded_file)
    w, h = img.size
    
    # Kh·ªüi t·∫°o t·ªça ƒë·ªô 1 l·∫ßn
    state_key = f"{key_prefix}_pts"
    if state_key not in st.session_state:
        st.session_state[state_key] = get_default_points(img, session)
        
    pts = st.session_state[state_key]
    
    st.markdown(f"#### üìê CƒÉn ch·ªânh {label}")
    st.info("K√©o thanh tr∆∞·ª£t sao cho 4 ch·∫•m m√†u n·∫±m ƒë√∫ng 4 g√≥c nh·ªçn c·ªßa th·∫ª.")

    # Hi·ªÉn th·ªã ·∫£nh h∆∞·ªõng d·∫´n
    preview = draw_guide(img, pts)
    st.image(preview, use_container_width=True)
    
    # Sliders ƒëi·ªÅu khi·ªÉn
    # Chia l√†m 2 c·ªôt: Tr√°i v√† Ph·∫£i
    c1, c2 = st.columns(2)
    
    with c1:
        st.markdown("**B√™n Tr√°i**")
        st.markdown("üî¥ **G√≥c Tr√™n-Tr√°i (ƒê·ªè)**")
        pts["tl"][0] = st.slider(f"X (Tr√°i-Ph·∫£i)", 0, w, pts["tl"][0], key=f"{key_prefix}_tl_x")
        pts["tl"][1] = st.slider(f"Y (L√™n-Xu·ªëng)", 0, h, pts["tl"][1], key=f"{key_prefix}_tl_y")
        
        st.markdown("üü° **G√≥c D∆∞·ªõi-Tr√°i (V√†ng)**")
        pts["bl"][0] = st.slider(f"X (Tr√°i-Ph·∫£i)", 0, w, pts["bl"][0], key=f"{key_prefix}_bl_x")
        pts["bl"][1] = st.slider(f"Y (L√™n-Xu·ªëng)", 0, h, pts["bl"][1], key=f"{key_prefix}_bl_y")

    with c2:
        st.markdown("**B√™n Ph·∫£i**")
        st.markdown("üü¢ **G√≥c Tr√™n-Ph·∫£i (Xanh L√°)**")
        pts["tr"][0] = st.slider(f"X (Tr√°i-Ph·∫£i)", 0, w, pts["tr"][0], key=f"{key_prefix}_tr_x")
        pts["tr"][1] = st.slider(f"Y (L√™n-Xu·ªëng)", 0, h, pts["tr"][1], key=f"{key_prefix}_tr_y")
        
        st.markdown("üîµ **G√≥c D∆∞·ªõi-Ph·∫£i (Xanh D∆∞∆°ng)**")
        pts["br"][0] = st.slider(f"X (Tr√°i-Ph·∫£i)", 0, w, pts["br"][0], key=f"{key_prefix}_br_x")
        pts["br"][1] = st.slider(f"Y (L√™n-Xu·ªëng)", 0, h, pts["br"][1], key=f"{key_prefix}_br_y")

    # C·∫≠p nh·∫≠t l·∫°i session
    st.session_state[state_key] = pts
    
    # X·ª≠ l√Ω c·∫Øt
    final_card = warp_perspective_manual(img, pts)
    return final_card

def main():
    st.markdown("<h1 style='text-align: center; color: #8e44ad;'>üÜî TOOL V15 (CAMSCANNER MODE)</h1>", unsafe_allow_html=True)
    st.caption("Ch·ªânh 4 g√≥c th·ªß c√¥ng - Kh√¥ng bao gi·ªù b·ªã m√©o")
    
    session = load_ai_session()
    
    col1, col2 = st.columns(2)
    with col1:
        f_file = st.file_uploader("M·∫∑t Tr∆∞·ªõc", type=['jpg','png','jpeg'], key="f_up")
    with col2:
        b_file = st.file_uploader("M·∫∑t Sau", type=['jpg','png','jpeg'], key="b_up")

    # X·ª≠ l√Ω t·ª´ng ·∫£nh
    img1_final = None
    img2_final = None

    if f_file:
        with st.expander("1. CH·ªàNH S·ª¨A M·∫∂T TR∆Ø·ªöC", expanded=True):
            img1_final = adjustment_ui("M·∫∑t Tr∆∞·ªõc", "front", f_file, session)
            if img1_final:
                st.image(img1_final, caption="K·∫øt qu·∫£ M·∫∑t Tr∆∞·ªõc", width=300)

    if b_file:
        with st.expander("2. CH·ªàNH S·ª¨A M·∫∂T SAU", expanded=False):
            img2_final = adjustment_ui("M·∫∑t Sau", "back", b_file, session)
            if img2_final:
                st.image(img2_final, caption="K·∫øt qu·∫£ M·∫∑t Sau", width=300)

    # N√∫t gh√©p
    if img1_final and img2_final:
        st.markdown("---")
        if st.button("üìÑ XU·∫§T FILE PDF", type="primary", use_container_width=True):
            with st.spinner("ƒêang t·∫°o PDF..."):
                # K√≠ch th∆∞·ªõc pixel chu·∫©n
                TARGET_W, TARGET_H = 1011, 638
                
                # Resize (D√π warp ƒë√£ chu·∫©n, resize l·∫°i l·∫ßn n·ªØa cho ch·∫Øc ch·∫Øn ƒë√∫ng size in)
                scan1 = img1_final.resize((TARGET_W, TARGET_H), Image.Resampling.LANCZOS)
                scan2 = img2_final.resize((TARGET_W, TARGET_H), Image.Resampling.LANCZOS)

                # A4 Canvas
                A4_W, A4_H = pixel_from_mm(210, 300), pixel_from_mm(297, 300)
                canvas = Image.new('RGB', (A4_W, A4_H), 'white')
                
                cx = A4_W // 2
                gap = 350
                sy = (A4_H - (TARGET_H * 2 + gap)) // 2 

                canvas.paste(scan1, (cx - TARGET_W // 2, sy))
                canvas.paste(scan2, (cx - TARGET_W // 2, sy + TARGET_H + gap))

                # Save
                pdf_buffer = io.BytesIO()
                canvas.save(pdf_buffer, "PDF", resolution=300.0)
                
                st.success("Th√†nh c√¥ng!")
                st.image(canvas, caption="File A4 Ho√†n Ch·ªânh", use_container_width=True)
                st.download_button("üì• T·∫¢I PDF NGAY", pdf_buffer.getvalue(), "CCCD_V15_Manual.pdf", "application/pdf", type="primary")

    st.markdown("---")
    st.markdown("<div style='text-align: center; color: grey;'>App created by C√† VƒÉn Kim - ATP</div>", unsafe_allow_html=True)

if __name__ == "__main__":
    main()